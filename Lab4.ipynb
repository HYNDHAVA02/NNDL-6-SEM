{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "zip_file = \"/content/train.zip\"  \n",
    "extract_folder = \"/content/trainimages\"  \n",
    "csv_file = \"/content/trainLabels.csv\" \n",
    "\n",
    "\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as archive:\n",
    "    archive.extractall(extract_folder)\n",
    "\n",
    "\n",
    "image_folder = \"/content/trainimages/train\" # Update based on extracted structure\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "def load_image(image_id, img_size=(28, 28)):\n",
    "    img_path = os.path.join(image_folder, f\"{image_id}.png\")  # Assuming PNG format\n",
    "    if os.path.exists(img_path):\n",
    "        img = imread(img_path)\n",
    "        img_resized = resize(img, img_size)  # Resize to 28x28\n",
    "        img_gray = rgb2gray(img_resized)  # Convert to grayscale\n",
    "        return img_gray\n",
    "    else:\n",
    "        print(f\"Image {image_id}.png not found!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img = load_image(row[\"id\"])\n",
    "    if img is not None:\n",
    "        X_data.append(img)\n",
    "        y_data.append(row[\"label\"])\n",
    "\n",
    "\n",
    "X_data = np.array(X_data).reshape(len(X_data), 28, 28, 1)  # Add channel dimension\n",
    "y_data = np.array(pd.factorize(y_data)[0])  # Convert labels to numbers\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), input_shape=(28, 28, 1), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nCNN Model Accuracy:', score[1])\n",
    "\n",
    "\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    plt.imshow(filters[:,:,0,i], cmap='gray')\n",
    "    plt.title(f\"Filter {i+1}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sample_image = X_train[10].reshape(28, 28)\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "filtered_image = signal.convolve2d(sample_image, filters[:,:,0,1].reshape(3,3), boundary='symm', mode='same')\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.title(\"Filtered Image\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fc_model = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "fc_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fc_history = fc_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "plt.plot(fc_history.history['loss'], label='Training Loss')\n",
    "plt.plot(fc_history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Fully Connected Network - Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fc_score = fc_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nFully Connected Network Accuracy:', fc_score[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
